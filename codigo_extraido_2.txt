===== Beginning of "C:\Users\ludso\OneDrive\Documentos\projetos_avulsos\ia_mL\sentinela_v2\app_k11.py" =====
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sqlalchemy import create_engine
from datetime import date
from models import engine

# ==============================================================================
# CONFIGURA√á√ÉO E CSS
# ==============================================================================
st.set_page_config(page_title="Sentinela AL 5.0", layout="wide", page_icon="üåµ")

st.markdown(
    """
<style>
    .metric-card {background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 10px; padding: 20px; text-align: center;}
    .badge-veterano {background-color: #28a745; color: white; padding: 4px 8px; border-radius: 4px; font-weight: bold;}
    .badge-novato {background-color: #17a2b8; color: white; padding: 4px 8px; border-radius: 4px; font-weight: bold;}
    .badge-intermitente {background-color: #ffc107; color: black; padding: 4px 8px; border-radius: 4px; font-weight: bold;}
    .alert-red {color: #dc3545; font-weight: bold;}
</style>
""",
    unsafe_allow_html=True,
)

def exibir_disclaimer():
    st.sidebar.markdown("---")
    with st.sidebar.expander("‚ÑπÔ∏è Sobre e Aviso Legal", expanded=False):
        st.markdown("""
        <div class='disclaimer-box'>
        <b>Autoria:</b><br>
        Projeto desenvolvido por <b>Ludson Almeida</b>, estudante de Ci√™ncia da Computa√ß√£o na UFAL (Universidade Federal de Alagoas).<br><br>
        <b>Objetivo:</b><br>
        Este programa trata-se de um projeto de portf√≥lio para experimenta√ß√£o em Visualiza√ß√£o e Engenharia de Dados. <b>N√£o possui v√≠nculo oficial</b> com a Assembleia Legislativa ou √≥rg√£os de controle.<br><br>
        <b>Fonte dos Dados:</b><br>
        Dados extra√≠dos automaticamente do portal p√∫blico: <a href='https://transparencia.al.al.leg.br/' target='_blank'>Transpar√™ncia ALE-AL</a>. A coleta √© feita de forma automatizada.<br><br>
        <b>Isen√ß√£o de Responsabilidade:</b><br>
        1. Podem ocorrer erros no processo de extra√ß√£o (OCR/HTML parsing) ou no tratamento dos dados.<br>
        2. Nenhuma conclus√£o deve ser tomada exclusivamente com base nesta ferramenta sem confer√™ncia na fonte oficial.<br>
        3. O autor n√£o se responsabiliza pelo uso indevido das informa√ß√µes aqui apresentadas.
        </div>
        """, unsafe_allow_html=True)

# ==============================================================================
# ETL: CARREGAMENTO
# ==============================================================================
@st.cache_data
def carregar_dados():
    # engine = create_engine("sqlite:///sentinela_alagoas.db")
    
    try:
        query = "SELECT * FROM historico_folha"
        df = pd.read_sql(query, engine)
    except Exception:
        return pd.DataFrame()

    # 1. Cria Data Base
    df["data_base"] = pd.to_datetime(
        df["ano_referencia"].astype(str)
        + "-"
        + df["mes_referencia"].astype(str)
        + "-01"
    )

    # 2. Extrai Sobrenome
    def extrair_sobrenome(nome):
        partes = str(nome).strip().upper().split()
        if not partes:
            return "DESCONHECIDO"
        ignorar = ["JUNIOR", "NETO", "FILHO", "SOBRINHO"]
        if len(partes) > 1 and partes[-1] in ignorar:
            return partes[-2]
        return partes[-1]

    df["sobrenome"] = df["nome"].apply(extrair_sobrenome)
    return df


@st.cache_data
def calcular_rotatividade(df):
    datas = sorted(df["data_base"].unique())
    resultados = []
    for i in range(1, len(datas)):
        mes_atual = datas[i]
        mes_anterior = datas[i - 1]
        nomes_atual = set(df[df["data_base"] == mes_atual]["nome"])
        nomes_anterior = set(df[df["data_base"] == mes_anterior]["nome"])
        entraram = len(nomes_atual - nomes_anterior)
        sairam = len(nomes_anterior - nomes_atual)
        resultados.append(
            {"data_base": mes_atual, "Admiss√µes": entraram, "Desligamentos": -sairam}
        )
    return pd.DataFrame(resultados)


@st.cache_data
def converter_para_csv(df):
    return df.to_csv(index=False).encode("utf-8")


# Carrega Dataframe
df_raw = carregar_dados()

if df_raw.empty:
    st.error("üö® Banco de dados vazio! Rode o 'ingestor_turbo.py' primeiro.")
    st.stop()

# ==============================================================================
# SIDEBAR: FILTROS OTIMIZADOS (com bot√£o de aplicar) - REPLACED
# ==============================================================================
st.sidebar.title("üéõÔ∏è Centro de Comando")

# Prepara valores padr√£o / limites usados pelo form
min_date = df_raw["data_base"].min().date()
max_date = df_raw["data_base"].max().date()
# lista ordenada de compet√™ncias (datas) para usar no select_slider
competencias = sorted(df_raw["data_base"].dt.date.unique())

anos_disponiveis = sorted(df_raw["data_base"].dt.year.unique(), reverse=True)
default_anos = anos_disponiveis[:1] if anos_disponiveis else []

# Inicializa filtro aplicado na sess√£o (persist√™ncia entre reruns)
if "filtro_aplicado" not in st.session_state:
    st.session_state.filtro_aplicado = {
        "modo": "Sele√ß√£o R√°pida (Por Ano)",
        "anos": default_anos,
        "range": (min_date, max_date),
    }

# --- FORMUL√ÅRIO: controles s√≥ s√£o efetivados quando o usu√°rio clica em "Aplicar" ---
with st.sidebar.form("filtro_temporal_form"):
    st.subheader("üìÖ Filtro Temporal")
    modo_filtro = st.radio(
        "M√©todo de Sele√ß√£o:",
        ["Sele√ß√£o R√°pida (Por Ano)", "Intervalo Preciso (Slider)"],
        index=(
            0 if st.session_state.filtro_aplicado["modo"].startswith("Sele√ß√£o") else 1
        ),
    )

    if modo_filtro == "Sele√ß√£o R√°pida (Por Ano)":
        anos_sel = st.multiselect(
            "Selecione os Anos:",
            options=anos_disponiveis,
            default=st.session_state.filtro_aplicado.get("anos", default_anos),
        )
    else:  # Intervalo Preciso (agora com select_slider por compet√™ncias)
        # valor padr√£o do range aplicado (se houver)
        default_range = st.session_state.filtro_aplicado.get(
            "range", (min_date, max_date)
        )
        # garante que os valores default existem dentro de 'competencias'
        # se n√£o existirem, usa os extremos
        start_default = (
            default_range[0] if default_range[0] in competencias else competencias[0]
        )
        end_default = (
            default_range[1] if default_range[1] in competencias else competencias[-1]
        )

        # select_slider com formato amig√°vel de m√™s/ano
        start_date, end_date = st.select_slider(
            "Arraste para definir in√≠cio e fim:",
            options=competencias,
            value=(start_default, end_default),
            format_func=lambda d: d.strftime("%m/%Y"),
        )

    # Bot√£o que efetiva o filtro ‚Äî visual mais simples
    aplicar = st.form_submit_button("Aplicar")

    # Quando o usu√°rio submete o form, atualizamos session_state.filtro_aplicado
    if aplicar:
        if modo_filtro == "Sele√ß√£o R√°pida (Por Ano)":
            if not anos_sel:
                st.sidebar.warning("Selecione pelo menos um ano.")
                # n√£o atualiza o filtro aplicado quando inv√°lido; mant√©m o anterior
            else:
                st.session_state.filtro_aplicado = {
                    "modo": modo_filtro,
                    "anos": anos_sel,
                    "range": (min_date, max_date),
                }
                st.sidebar.success(f"Filtro aplicado: {len(anos_sel)} ano(s).")
        else:
            st.session_state.filtro_aplicado = {
                "modo": modo_filtro,
                "anos": None,
                "range": (start_date, end_date),
            }
            st.sidebar.success(
                f"Filtro aplicado: {start_date.strftime('%m/%Y')} ‚Äî {end_date.strftime('%m/%Y')}"
            )

# --- A an√°lise usa o √∫ltimo filtro armazenado em session_state.filtro_aplicado ---
f = st.session_state.filtro_aplicado
if f["modo"] == "Sele√ß√£o R√°pida (Por Ano)":
    if f.get("anos"):
        df_filtered = df_raw[df_raw["data_base"].dt.year.isin(f["anos"])]
    else:
        df_filtered = df_raw.copy()
else:
    start_date, end_date = f.get("range", (min_date, max_date))
    mask = (df_raw["data_base"].dt.date >= start_date) & (
        df_raw["data_base"].dt.date <= end_date
    )
    df_filtered = df_raw.loc[mask]


# Resumo do Filtro
st.sidebar.info(
    f"Analisando **{len(df_filtered):,}** registros em **{df_filtered['data_base'].nunique()}** compet√™ncias."
)

# Bot√£o de Exporta√ß√£o Global
st.sidebar.markdown("---")
csv_filtrado = converter_para_csv(df_filtered)
st.sidebar.download_button(
    label="üì• Baixar Sele√ß√£o Atual (.csv)",
    data=csv_filtrado,
    file_name="sentinela_dados_selecao.csv",
    mime="text/csv",
)

exibir_disclaimer()

# ==============================================================================
# DASHBOARD
# ==============================================================================
st.title("üåµ Sentinela Alagoas")

tab1, tab2, tab3, tab4, tab5 = st.tabs(
    [
        "üìà Macro & Radar",
        "üîÑ Din√¢mica de RH",
        "üß¨ Grupos & Ganhos",
        "üïµÔ∏è Detetive Individual",
        "üéØ Radar de Anomalias",
    ]
)

# ------------------------------------------------------------------------------
# TAB 1: MACRO E RADAR DE ANOMALIAS (Recuperado!)
# ------------------------------------------------------------------------------
with tab1:
    col1, col2, col3 = st.columns(3)
    custo_total = df_filtered["rendimento_liquido"].sum()
    media_mensal = df_filtered.groupby("data_base")["rendimento_liquido"].sum().mean()

    col1.metric("Custo Total (Sele√ß√£o)", f"R$ {custo_total/1e6:,.1f} Mi")
    col2.metric("M√©dia Mensal da Folha", f"R$ {media_mensal/1e6:,.1f} Mi")
    col3.metric("Total de CPFs Distintos", f"{df_filtered['nome'].nunique()}")

    st.markdown("---")

    # 1. Gr√°fico de Evolu√ß√£o (Eixo Duplo)
    st.subheader("üìä Evolu√ß√£o: Dinheiro vs. Pessoas")
    df_agrupado = (
        df_filtered.groupby("data_base")
        .agg({"rendimento_liquido": "sum", "nome": "nunique"})
        .reset_index()
    )

    fig_dual = go.Figure()
    fig_dual.add_trace(
        go.Bar(
            x=df_agrupado["data_base"],
            y=df_agrupado["rendimento_liquido"],
            name="Custo L√≠quido (R$)",
            marker_color="#0052cc",
            yaxis="y",
        )
    )
    fig_dual.add_trace(
        go.Scatter(
            x=df_agrupado["data_base"],
            y=df_agrupado["nome"],
            name="Funcion√°rios",
            mode="lines+markers",
            line=dict(color="#ff2b2b", width=3),
            yaxis="y2",
        )
    )
    fig_dual.update_layout(
        yaxis=dict(title="Custo (R$)", side="left", showgrid=False),
        yaxis2=dict(title="Qtd. Pessoas", side="right", overlaying="y", showgrid=False),
        legend=dict(x=0.01, y=0.99),
        hovermode="x unified",
        margin=dict(l=0, r=0, t=30, b=0),
    )
    st.plotly_chart(fig_dual, use_container_width=True)

    # Bot√£o de exporta√ß√£o dos dados macro
    csv_macro = converter_para_csv(df_agrupado)
    st.download_button(
        label="üì• Exportar dados macro (CSV)",
        data=csv_macro,
        file_name="macro_evolucao.csv",
        mime="text/csv",
    )


# ------------------------------------------------------------------------------
# TAB 2: DIN√ÇMICA DE RH
# ------------------------------------------------------------------------------
with tab2:
    st.subheader("üîÑ Rotatividade (Turnover)")
    df_turnover = calcular_rotatividade(df_filtered)

    if not df_turnover.empty:
        fig_turn = go.Figure()
        fig_turn.add_trace(
            go.Bar(
                x=df_turnover["data_base"],
                y=df_turnover["Admiss√µes"],
                name="Entradas",
                marker_color="green",
            )
        )
        fig_turn.add_trace(
            go.Bar(
                x=df_turnover["data_base"],
                y=df_turnover["Desligamentos"],
                name="Sa√≠das",
                marker_color="red",
            )
        )
        fig_turn.update_layout(
            barmode="relative", title="Fluxo de Contrata√ß√µes e Exonera√ß√µes"
        )
        st.plotly_chart(fig_turn, use_container_width=True)
        # Bot√£o de exporta√ß√£o dos dados de turnover logo abaixo do gr√°fico
        csv_turnover = converter_para_csv(df_turnover)
        st.download_button(
            label="üì• Exportar dados de rotatividade (CSV)",
            data=csv_turnover,
            file_name="rotatividade.csv",
            mime="text/csv",
        )
    else:
        st.info("Selecione um per√≠odo maior que 1 m√™s para ver a rotatividade.")

    st.markdown("---")
    c_alert, c_export = st.columns([3, 1])
    c_alert.subheader("üö® Progress√µes de Carreira (> 20%)")

    df_sorted = df_filtered.sort_values(["nome", "data_base"])
    df_sorted["salario_anterior"] = df_sorted.groupby("nome")[
        "rendimento_liquido"
    ].shift(1)
    df_sorted["delta_perc"] = (
        (df_sorted["rendimento_liquido"] - df_sorted["salario_anterior"])
        / df_sorted["salario_anterior"]
    ) * 100

    progredidos = df_sorted[
        (df_sorted["delta_perc"] > 20) & (df_sorted["rendimento_liquido"] > 5000)
    ].sort_values("delta_perc", ascending=False)

    if not progredidos.empty:
        csv_progredidos = converter_para_csv(
            progredidos[
                [
                    "data_base",
                    "nome",
                    "cargo",
                    "salario_anterior",
                    "rendimento_liquido",
                    "delta_perc",
                ]
            ]
        )
        c_export.download_button(
            label="‚ö†Ô∏è Baixar Relat√≥rio",
            data=csv_progredidos,
            file_name="progressoes_carreira.csv",
            mime="text/csv",
        )
        st.dataframe(
            progredidos[
                [
                    "data_base",
                    "nome",
                    "cargo",
                    "salario_anterior",
                    "rendimento_liquido",
                    "delta_perc",
                ]
            ].style.format(
                {
                    "salario_anterior": "R$ {:.2f}",
                    "rendimento_liquido": "R$ {:.2f}",
                    "delta_perc": "{:.1f}%",
                }
            )
        )
    else:
        st.success("Nenhuma anomalia de aumento detectada.")

# ------------------------------------------------------------------------------
# TAB 3: CL√ÉS
# ------------------------------------------------------------------------------
with tab3:
    st.subheader("üè∞ Sobrenomes Comuns")
    ignorar = [
        "SILVA",
        "SANTOS",
        "OLIVEIRA",
        "SOUZA",
        "LIMA",
        "COSTA",
        "PEREIRA",
        "ALVES",
        "FERREIRA",
        "RODRIGUES",
    ]
    df_clans = df_filtered[~df_filtered["sobrenome"].isin(ignorar)]
    top_clans = (
        df_clans.groupby("sobrenome")["nome"]
        .nunique()
        .sort_values(ascending=False)
        .head(15)
    )
    fig_clan = px.bar(top_clans, orientation="h", color_discrete_sequence=["#6610f2"])
    fig_clan.update_layout(yaxis={"categoryorder": "total ascending"})

    st.plotly_chart(fig_clan, use_container_width=True)
    # Bot√£o de exporta√ß√£o dos dados de cl√£s
    csv_clans = converter_para_csv(top_clans.reset_index())
    st.download_button(
        label="üì• Exportar dados de sobrenomes (CSV)",
        data=csv_clans,
        file_name="sobrenomes_comuns.csv",
        mime="text/csv",
    )

    st.subheader("üí∞ Ranking Acumulado")
    ocultar = st.checkbox("Ocultar Deputados", value=True)
    n_top = st.number_input(
        "Nomes no ranking:", min_value=1, max_value=100, value=15, step=1
    )
    df_rank = df_filtered.copy()
    if ocultar:
        df_rank = df_rank[~df_rank["cargo"].str.contains("DEPUTADO", case=False)]
    soma = df_rank.groupby(["nome", "cargo"])["rendimento_liquido"].sum().reset_index()
    fig_rank = px.bar(
        soma.nlargest(int(n_top), "rendimento_liquido"),
        x="rendimento_liquido",
        y="nome",
        orientation="h",
        text_auto=".2s",
        color="cargo",
    )
    fig_rank.update_layout(yaxis={"categoryorder": "total ascending"})
    st.plotly_chart(fig_rank, use_container_width=True)
    # Bot√£o de exporta√ß√£o dos dados de ranking acumulado
    csv_ranking = converter_para_csv(soma.nlargest(int(n_top), "rendimento_liquido"))
    st.download_button(
        label="üì• Exportar ranking acumulado (CSV)",
        data=csv_ranking,
        file_name="ranking_acumulado.csv",
        mime="text/csv",
    )

# ------------------------------------------------------------------------------
# TAB 4: DETETIVE
# ------------------------------------------------------------------------------
with tab4:
    st.subheader("üîç Investiga√ß√£o Individual")
    nome_sel = st.selectbox("Buscar Servidor:", [""] + sorted(df_raw["nome"].unique()))

    if nome_sel:
        df_pessoa = df_raw[df_raw["nome"] == nome_sel].sort_values("data_base")
        total_meses = df_raw["data_base"].nunique()
        meses_pessoa = df_pessoa["data_base"].nunique()

        badge = (
            "üî∞ VETERANO"
            if meses_pessoa >= (total_meses * 0.8)
            else "üÜï NOVATO" if meses_pessoa <= 3 else "üîÑ REGULAR"
        )
        st.markdown(f"### {nome_sel} ({badge})")

        # Comparativo
        cargo_atual = df_pessoa.iloc[-1]["cargo"]
        df_media = (
            df_raw[df_raw["cargo"] == cargo_atual]
            .groupby("data_base")["rendimento_liquido"]
            .mean()
            .reset_index()
        )
        df_merged = pd.merge(
            df_pessoa, df_media, on="data_base", how="left", suffixes=("", "_media")
        )

        fig_comp = go.Figure()
        fig_comp.add_trace(
            go.Scatter(
                x=df_merged["data_base"],
                y=df_merged["rendimento_liquido_media"],
                name=f"M√©dia ({cargo_atual})",
                line=dict(color="gray", dash="dash"),
            )
        )
        fig_comp.add_trace(
            go.Scatter(
                x=df_merged["data_base"],
                y=df_merged["rendimento_liquido"],
                name="Servidor",
                mode="lines+markers",
                line=dict(color="blue", width=3),
            )
        )
        st.plotly_chart(fig_comp, use_container_width=True)

        st.dataframe(
            df_pessoa[
                [
                    "data_base",
                    "cargo",
                    "rendimento_liquido",
                    "total_creditos",
                    "total_debitos",
                ]
            ].style.format({"rendimento_liquido": "R$ {:.2f}"})
        )
        # Bot√£o de exporta√ß√£o dos dados individuais
        csv_pessoa = converter_para_csv(
            df_pessoa[
                [
                    "data_base",
                    "cargo",
                    "rendimento_liquido",
                    "total_creditos",
                    "total_debitos",
                ]
            ]
        )
        st.download_button(
            label="üì• Exportar dados do servidor (CSV)",
            data=csv_pessoa,
            file_name=f"dados_{nome_sel.replace(' ', '_')}.csv",
            mime="text/csv",
        )

with tab5:
    st.subheader("üéØ Radar de Anomalias")
    st.info(
        "Este gr√°fico mostra a distribui√ß√£o. Pontos muito √† direita s√£o sal√°rios altos."
    )

    if modo_filtro == "Sele√ß√£o R√°pida (Por Ano)":
        if not df_filtered.empty:
            # Adiciona seletor de m√™s
            meses_disponiveis = (
                df_filtered["data_base"]
                .dt.to_period("M")
                .drop_duplicates()
                .sort_values()
            )
            meses_str = [str(m) for m in meses_disponiveis]
            mes_sel_str = st.selectbox(
                "Selecione o m√™s:", options=meses_str, index=len(meses_str) - 1
            )
            mes_sel = pd.Period(mes_sel_str)
            # Filtra para o m√™s selecionado
            mask_mes = df_filtered["data_base"].dt.to_period("M") == mes_sel
            df_mes = df_filtered[mask_mes]

            if not df_mes.empty:
                fig_scatter = px.scatter(
                    df_mes,
                    x="rendimento_liquido",
                    y="cargo",
                    hover_data=["nome"],
                    color="rendimento_liquido",
                    color_continuous_scale="Bluered",
                )
                fig_scatter.update_yaxes(
                    showticklabels=False
                )  # Esconde nomes dos cargos pra n√£o poluir
                st.plotly_chart(fig_scatter, use_container_width=True)
                # Bot√£o de exporta√ß√£o dos dados de anomalias
                csv_anomalias = converter_para_csv(df_mes)
                st.download_button(
                    label="üì• Exportar dados do m√™s selecionado (CSV)",
                    data=csv_anomalias,
                    file_name=f"anomalias_{mes_sel_str}.csv",
                    mime="text/csv",
                )
            else:
                st.warning("N√£o h√° dados para o m√™s selecionado.")
        else:
            st.warning("N√£o h√° dados para o m√™s selecionado.")

===== End of "C:\Users\ludso\OneDrive\Documentos\projetos_avulsos\ia_mL\sentinela_v2\app_k11.py" =====


===== Beginning of "C:\Users\ludso\OneDrive\Documentos\projetos_avulsos\ia_mL\sentinela_v2\ingestor_turbo.py" =====
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import urllib3
from io import StringIO
from sqlalchemy.exc import IntegrityError
from concurrent.futures import ThreadPoolExecutor, as_completed
from models import Session, Funcionario, init_db


BASE_URL = "https://transparencia.al.al.leg.br"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# Cria uma sess√£o global para reaproveitar conex√µes (muito mais r√°pido)
session_http = requests.Session()
session_http.headers.update(HEADERS)


def get_links_mes(ano, mes):
    """Busca a lista de nomes (Processo Sequencial Obrigat√≥rio)"""
    codigo_folha = f"{ano}{mes:02d}%7CEM"
    url = f"{BASE_URL}/?arg=&folha={codigo_folha}"

    print(f"Baixando lista mestra: {mes}/{ano}...")
    try:
        response = session_http.get(url, timeout=20)
        if "Nenhum resultado" in response.text:
            print(f"\tSem dados para {mes}/{ano}.")
            return []

        soup = BeautifulSoup(response.content, "html.parser")
        funcionarios = []

        for link in soup.find_all("a", href=True):
            if "detalhar.php" in link["href"] and len(link.text.strip()) > 3:
                full_url = (
                    link["href"]
                    if link["href"].startswith("http")
                    else f'{BASE_URL}/{link["href"]}'
                )
                funcionarios.append({"nome": link.text.strip(), "url": full_url})

        return funcionarios
    except Exception as e:
        print(f"\tErro de conex√£o na lista: {e}")
        return []


def processar_funcionario_individual(func_info):
    """
    Fun√ß√£o que ser√° rodada em parelelo.
    Ela N√ÉO salva no banco, apenas baixa e retorna os dados processados.
    """
    try:
        response = session_http.get(func_info["url"], timeout=15)
        # Check r√°pido de erro
        if response.status_code != 200:
            return None

        html_io = StringIO(response.text)
        dfs = pd.read_html(html_io, match="Rendimento", decimal=",", thousands=".")

        if dfs:
            df = dfs[0]
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(-1)
            df = df.loc[:, ~df.columns.duplicated()]

            # --- L√≥gica de Limpeza (Corrigida) ---
            def limpar_valor(coluna):
                if coluna not in df.columns:
                    return 0.0
                val = df[coluna].iloc[0]

                # Se o Pandas j√° converteu para float/int, retorna direto
                if isinstance(val, (int, float)):
                    return float(val)

                # Se for string suja
                val_str = str(val).strip()
                val_str = val_str.replace("R$", "").strip()
                val_str = val_str.replace(".", "")
                val_str = val_str.replace(",", ".")
                return float(val_str) if val_str else 0.0

            # Retorna um dicion√°rio com os dados prontos
            return {
                "nome": func_info["nome"],
                "cargo": (
                    str(df["Cargo"].iloc[0]).upper()
                    if "Cargo" in df.columns
                    else "DESCONHECIDO"
                ),
                "rendimento_liquido": limpar_valor("Rendimento L√≠quido"),
                "total_creditos": limpar_valor("Total de Cr√©ditos"),
                "total_debitos": limpar_valor("Total de D√©bitos"),
                "url_origem": func_info["url"],
            }

    except Exception:
        # Erros individuais s√£o ignorados para n√£o parar o fluxo
        pass

    return None


def ingestor_turbo(ano_inicio, ano_fim):
    db_session = Session()
    total_global = 0

    # Loop de Anos/Meses
    for ano in range(ano_fim, ano_inicio - 1, -1):
        for mes in range(12, 0, -1):
            if ano == 2025 and mes > 11:
                continue

            # 1. Pega a lista de URLs (Isso tem que ser um por um)
            lista_raw = get_links_mes(ano, mes)
            if not lista_raw:
                continue

            # 2. Filtra quem j√° temos no banco (Cache Baseado em URL)
            urls_existentes = (
                db_session.query(Funcionario.url_origem)
                .filter_by(mes_referencia=mes, ano_referencia=ano)
                .all()
            )
            # Cria um conjunto (set) com as URLs que j√° baixamos
            urls_set = {u[0] for u in urls_existentes}

            # S√≥ baixa se a URL ainda n√£o estiver no banco
            lista_para_baixar = [f for f in lista_raw if f["url"] not in urls_set]

            total_mes = len(lista_raw)
            a_baixar = len(lista_para_baixar)

            if a_baixar == 0:
                print(
                    f"\tM√™s {mes}/{ano} j√° est√° completo no banco ({total_mes} registros)."
                )
                continue

            print(
                f"Turbinando {mes}/{ano}: Baixando {a_baixar} novos (de {total_mes})..."
            )

            # 3. O PULO DO GATO: ThreadPoolExecutor
            # max_workers=10 significa 10 conex√µes simult√¢neas.
            # N√£o coloque muito alto (ex: 50) sen√£o o servidor te bloqueia.
            resultados_para_salvar = []

            with ThreadPoolExecutor(max_workers=10) as executor:
                # Dispara as tarefas
                future_to_func = {
                    executor.submit(processar_funcionario_individual, f): f
                    for f in lista_para_baixar
                }

                completos = 0
                for future in as_completed(future_to_func):
                    dados = future.result()
                    completos += 1

                    # Barra de progresso visual
                    print(
                        f"\tProcessando: {completos}/{a_baixar} ({(completos/a_baixar):.1%})",
                        end="\r",
                    )

                    if dados:
                        resultados_para_salvar.append(dados)

            # 4. Salva tudo no banco de uma vez (Batch Insert)
            print(f"\n\tSalvando {len(resultados_para_salvar)} registros no banco...")

            for d in resultados_para_salvar:
                try:
                    novo = Funcionario(
                        nome=d["nome"],
                        cargo=d["cargo"],
                        rendimento_liquido=d["rendimento_liquido"],
                        total_creditos=d["total_creditos"],
                        total_debitos=d["total_debitos"],
                        mes_referencia=mes,
                        ano_referencia=ano,
                        url_origem=d["url_origem"],
                    )
                    db_session.add(novo)
                    db_session.commit()
                except IntegrityError:
                    db_session.rollback()
                except Exception as e:
                    db_session.rollback()
                    print(f"\tErro ao salvar registro: {e}")

            try:
                db_session.commit()
                total_global += len(resultados_para_salvar)
                print(f"\tM√™s {mes}/{ano} finalizado com sucesso!")
            except Exception as e:
                db_session.rollback()
                print(f"\tErro ao salvar lote: {e}")

    db_session.close()
    print(f"\nFim Turbo. Total salvo: {total_global}")


if __name__ == "__main__":
    init_db()
    # Atualiza at√© o m√™s atual automaticamente
    from datetime import datetime

    ano_atual = datetime.now().year
    ingestor_turbo(2020, ano_atual)

===== End of "C:\Users\ludso\OneDrive\Documentos\projetos_avulsos\ia_mL\sentinela_v2\ingestor_turbo.py" =====


===== Beginning of "C:\Users\ludso\OneDrive\Documentos\projetos_avulsos\ia_mL\sentinela_v2\models.py" =====
from sqlalchemy import (
    create_engine,
    Column,
    Integer,
    String,
    Float,
    Date,
    UniqueConstraint,
)
from sqlalchemy.orm import declarative_base, sessionmaker
from datetime import date
import os

DB_NAME = "sentinela_alagoas.db"
DATABASE_URL = os.environ.get("DATABASE_URL") or f"sqlite:///{DB_NAME}"
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=5,
    max_overflow=10,
    connect_args=(
        {"check_same_thread": False} if DATABASE_URL.startswith("sqlite") else {}
    ),
)
Session = sessionmaker(bind=engine)
Base = declarative_base()


class Funcionario(Base):
    __tablename__ = "historico_folha"

    id = Column(Integer, primary_key=True)
    nome = Column(String, index=True)
    cargo = Column(String, index=True)

    rendimento_liquido = Column(Float)
    total_creditos = Column(Float)
    total_debitos = Column(Float)

    mes_referencia = Column(Integer, index=True)
    ano_referencia = Column(Integer, index=True)

    data_coleta = Column(Date, default=date.today)
    # A URL passa a ser obrigat√≥ria e √∫nica
    url_origem = Column(String, nullable=False, unique=True)

    # REMOVEMOS a restri√ß√£o antiga de nomes duplicados
    # Agora a √∫nica restri√ß√£o √© n√£o repetir a mesma URL (mesmo contracheque)
    __table_args__ = (UniqueConstraint("url_origem", name="unico_por_url"),)


def init_db():
    Base.metadata.create_all(engine)
    print(f"Banco de dados '{DB_NAME}' pronto (Vers√£o Anti-Hom√¥nimos)!")


if __name__ == "__main__":
    init_db()

===== End of "C:\Users\ludso\OneDrive\Documentos\projetos_avulsos\ia_mL\sentinela_v2\models.py" =====


===== Beginning of "C:\Users\ludso\OneDrive\Documentos\projetos_avulsos\ia_mL\sentinela_v2\.github\workflows\atualiza√ß√£o_mensal.yml" =====
name: Atualiza√ß√£o Mensal - Sentinela

on:
  schedule:
    # Dia 10 de todo m√™s √†s 03:00 UTC (meia-noite no Brasil)
    - cron: '0 3 10 * *'
  workflow_dispatch: # permite rodar manualmente

jobs:
  ingestor:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout do reposit√≥rio
        uses: actions/checkout@v4

      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Instalar depend√™ncias
        run: |
          pip install -r requirements.txt

      - name: Rodar Ingestor Mensal
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python ingestor_turbo.py

===== End of "C:\Users\ludso\OneDrive\Documentos\projetos_avulsos\ia_mL\sentinela_v2\.github\workflows\atualiza√ß√£o_mensal.yml" =====


